{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:43:48.763271Z",
     "start_time": "2023-12-09T16:43:44.972183Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "img_size=(240, 320)\n",
    "img_channels = 3\n",
    "batch_size=32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:43:48.769003Z",
     "start_time": "2023-12-09T16:43:48.763839Z"
    }
   },
   "id": "c902b5ffcc0be518"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = 'simple_covnet_model.h5'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8119c7b1f46208d2"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "validation_size = 500\n",
    "test_size = 500"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:51:00.363557Z",
     "start_time": "2023-12-09T16:51:00.357317Z"
    }
   },
   "id": "57836484d49b556a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the DataSet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a698c6c6147e952e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataset citation:\n",
    "- From Semi-Supervised to Transfer Counting of Crowds\n",
    "C. C. Loy, S. Gong, and T. Xiang\n",
    "in Proceedings of IEEE International Conference on Computer Vision, pp. 2256-2263, 2013 (ICCV)\n",
    "- Cumulative Attribute Space for Age and Crowd Density Estimation\n",
    "K. Chen, S. Gong, T. Xiang, and C. C. Loy\n",
    "in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 2467-2474, 2013 (CVPR, Oral)\n",
    "- Crowd Counting and Profiling: Methodology and Evaluation\n",
    "C. C. Loy, K. Chen, S. Gong, T. Xiang\n",
    "in S. Ali, K. Nishino, D. Manocha, and M. Shah (Eds.), Modeling, Simulation and Visual Analysis of Crowds, Springer, vol. 11, pp. 347-382, 2013\n",
    "- Feature Mining for Localised Crowd Counting\n",
    "K. Chen, C. C. Loy, S. Gong, and T. Xiang\n",
    "British Machine Vision Conference, 2012 (BMVC)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3148fc7158b3013"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset_path = '/Users/olove/Library/CloudStorage/OneDrive-Personal/AI datasets/CrowdCounter'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:43:48.769459Z",
     "start_time": "2023-12-09T16:43:48.766044Z"
    }
   },
   "id": "2a61029b86dd4523"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "      count      image_name\n0        35  seq_000001.jpg\n1        41  seq_000002.jpg\n2        41  seq_000003.jpg\n3        44  seq_000004.jpg\n4        41  seq_000005.jpg\n...     ...             ...\n1995     27  seq_001996.jpg\n1996     27  seq_001997.jpg\n1997     25  seq_001998.jpg\n1998     26  seq_001999.jpg\n1999     26  seq_002000.jpg\n\n[2000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35</td>\n      <td>seq_000001.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>41</td>\n      <td>seq_000002.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>seq_000003.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44</td>\n      <td>seq_000004.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41</td>\n      <td>seq_000005.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>27</td>\n      <td>seq_001996.jpg</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>27</td>\n      <td>seq_001997.jpg</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>25</td>\n      <td>seq_001998.jpg</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>26</td>\n      <td>seq_001999.jpg</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>26</td>\n      <td>seq_002000.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(dataset_path + '/labels.csv')\n",
    "labels_df['image_name'] = labels_df['id'].map('seq_{:06d}.jpg'.format)\n",
    "labels_df.drop(\"id\", axis=1,inplace=True)\n",
    "display(labels_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:43:49.284136Z",
     "start_time": "2023-12-09T16:43:49.269399Z"
    }
   },
   "id": "d2dae3a51c2c8948"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e7301d83edda066c"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "      count      image_name\n0        25  seq_000943.jpg\n1        24  seq_000645.jpg\n2        20  seq_000533.jpg\n3        22  seq_000627.jpg\n4        29  seq_001303.jpg\n...     ...             ...\n1995     19  seq_000653.jpg\n1996     18  seq_000474.jpg\n1997     38  seq_000187.jpg\n1998     26  seq_000190.jpg\n1999     19  seq_000436.jpg\n\n[2000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>seq_000943.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24</td>\n      <td>seq_000645.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20</td>\n      <td>seq_000533.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22</td>\n      <td>seq_000627.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29</td>\n      <td>seq_001303.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>19</td>\n      <td>seq_000653.jpg</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>18</td>\n      <td>seq_000474.jpg</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>38</td>\n      <td>seq_000187.jpg</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>26</td>\n      <td>seq_000190.jpg</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>19</td>\n      <td>seq_000436.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_df = labels_df.sample(frac=1).reset_index(drop=True)\n",
    "display(labels_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:49:45.428427Z",
     "start_time": "2023-12-09T16:49:45.423328Z"
    }
   },
   "id": "1d34f79116ad0d0a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "if (train_size+validation_size+test_size) != len(labels_df):\n",
    "    print('Dataset size is different from specified class sizes')\n",
    "    exit(1)\n",
    "\n",
    "training_df = labels_df[:train_size]\n",
    "validation_df = labels_df[train_size:train_size+validation_size]\n",
    "test_df = labels_df[train_size+validation_size:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:43:50.684036Z",
     "start_time": "2023-12-09T16:43:50.679595Z"
    }
   },
   "id": "68ffbd06d94921cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73cb3d24c1555a7b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape= img_size + (img_channels,))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:43:51.404820Z",
     "start_time": "2023-12-09T16:43:51.394655Z"
    }
   },
   "id": "d448c07728ee1f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Simple Covnet\n",
    "\n",
    "Downsizing using strides instead of MaxPolling in order to conserve location data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bce077d02d7424f9"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, strides=2, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "# x = layers.Dropout(0.5)(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:46:56.910154Z",
     "start_time": "2023-12-09T16:46:56.890699Z"
    }
   },
   "id": "8e87c1bf0eed10e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Output Layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35ca745a6e1390d9"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "outputs = layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = layers.Dropout(0.5)(outputs)\n",
    "outputs = layers.Dense(1)(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:46:57.692985Z",
     "start_time": "2023-12-09T16:46:57.661926Z"
    }
   },
   "id": "2d3e86c32901040b"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:46:58.098957Z",
     "start_time": "2023-12-09T16:46:58.095576Z"
    }
   },
   "id": "6e5f9a14eaffc43a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 240, 320, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 119, 159, 32)      896       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 59, 79, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 29, 39, 128)       73856     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 144768)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               18530432  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18623809 (71.04 MB)\n",
      "Trainable params: 18623809 (71.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:46:59.687428Z",
     "start_time": "2023-12-09T16:46:59.676710Z"
    }
   },
   "id": "e5dd3df119d8e3d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b6eb6db3c2d9a8ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2300381ac22fbd71"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=[\"mae\"])\n",
    "# TODO: Try mae vs accuracy. mae should be better since we are adjusting it to get closer to the actual value"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6a1a37a09407565"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\", patience=4\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_name,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b63b6dd1a1758bf6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels,\n",
    "        epochs=10,\n",
    "        callbacks = callbacks_list,\n",
    "        validation_data=(val_images, val_labels)\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3534ba093b0133c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
