{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:49.728668Z",
     "start_time": "2024-01-02T13:02:45.511317Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.layers as layers\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy as sc\n",
    "\n",
    "import training_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "img_size = (240, 320)\n",
    "img_channels = 3\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "display_epochs = (0, 100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:14:31.100403Z",
     "start_time": "2024-01-02T13:14:31.079579Z"
    }
   },
   "id": "c902b5ffcc0be518"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model_name = 'VGG16_(256).tf'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:49.734681Z",
     "start_time": "2024-01-02T13:02:49.732160Z"
    }
   },
   "id": "8119c7b1f46208d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_size = 1400\n",
    "validation_size = 500\n",
    "test_size = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:49.737439Z",
     "start_time": "2024-01-02T13:02:49.734712Z"
    }
   },
   "id": "57836484d49b556a",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the DataSet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a698c6c6147e952e"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a3148fc7158b3013"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dataset_path = '/Users/olove/Library/CloudStorage/OneDrive-Personal/AI datasets/CrowdCounter'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:49.739542Z",
     "start_time": "2024-01-02T13:02:49.736709Z"
    }
   },
   "id": "2a61029b86dd4523"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "      count      image_name\n0        35  seq_000001.jpg\n1        41  seq_000002.jpg\n2        41  seq_000003.jpg\n3        44  seq_000004.jpg\n4        41  seq_000005.jpg\n...     ...             ...\n1995     27  seq_001996.jpg\n1996     27  seq_001997.jpg\n1997     25  seq_001998.jpg\n1998     26  seq_001999.jpg\n1999     26  seq_002000.jpg\n\n[2000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35</td>\n      <td>seq_000001.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>41</td>\n      <td>seq_000002.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>seq_000003.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44</td>\n      <td>seq_000004.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41</td>\n      <td>seq_000005.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>27</td>\n      <td>seq_001996.jpg</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>27</td>\n      <td>seq_001997.jpg</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>25</td>\n      <td>seq_001998.jpg</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>26</td>\n      <td>seq_001999.jpg</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>26</td>\n      <td>seq_002000.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(dataset_path + '/labels.csv')\n",
    "labels_df['image_name'] = labels_df['id'].map('seq_{:06d}.jpg'.format)\n",
    "labels_df.drop(\"id\", axis=1, inplace=True)\n",
    "display(labels_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:49.769912Z",
     "start_time": "2024-01-02T13:02:49.738844Z"
    }
   },
   "id": "d2dae3a51c2c8948"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e7301d83edda066c"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "      count      image_name\n0        31  seq_000963.jpg\n1        37  seq_000373.jpg\n2        33  seq_001265.jpg\n3        43  seq_000985.jpg\n4        35  seq_000131.jpg\n...     ...             ...\n1995     36  seq_001110.jpg\n1996     24  seq_001416.jpg\n1997     34  seq_001777.jpg\n1998     30  seq_001445.jpg\n1999     29  seq_000881.jpg\n\n[2000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>seq_000963.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>seq_000373.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>seq_001265.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>43</td>\n      <td>seq_000985.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35</td>\n      <td>seq_000131.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>36</td>\n      <td>seq_001110.jpg</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>24</td>\n      <td>seq_001416.jpg</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>34</td>\n      <td>seq_001777.jpg</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>30</td>\n      <td>seq_001445.jpg</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>29</td>\n      <td>seq_000881.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_df = labels_df.sample(frac=1).reset_index(drop=True)\n",
    "display(labels_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:49.771102Z",
     "start_time": "2024-01-02T13:02:49.752955Z"
    }
   },
   "id": "1d34f79116ad0d0a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if (train_size + validation_size + test_size) != len(labels_df):\n",
    "    print('Dataset size is different from specified class sizes')\n",
    "    exit(1)\n",
    "\n",
    "training_df = labels_df[:train_size]\n",
    "validation_df = labels_df[train_size:train_size + validation_size].reset_index(drop=True)\n",
    "test_df = labels_df[train_size + validation_size:].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:49.772060Z",
     "start_time": "2024-01-02T13:02:49.757532Z"
    }
   },
   "id": "889e8ad596fb196f",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73cb3d24c1555a7b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=img_size + (img_channels,))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:49.772956Z",
     "start_time": "2024-01-02T13:02:49.759630Z"
    }
   },
   "id": "d448c07728ee1f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Simple Covnet\n",
    "\n",
    "Downsizing using strides instead of MaxPolling in order to conserve location data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bce077d02d7424f9"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def basic_covnet_block(input):\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, strides=2, activation=\"relu\")(input)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:49.773869Z",
     "start_time": "2024-01-02T13:02:49.766695Z"
    }
   },
   "id": "8e87c1bf0eed10e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Depthwise Seperable Convolution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1da23abeddeb6f9f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def custom_depthwise_conv_block(input, sizes, repeat_per_size, stride=1, pooling=False, dropout=False, residual=False):\n",
    "    x = input\n",
    "\n",
    "    previous_block_activation = x\n",
    "\n",
    "    for size in sizes:\n",
    "        for i in range(repeat_per_size - 1):\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Activation(\"relu\")(x)\n",
    "            x = layers.SeparableConv2D(size, 3, padding='same', use_bias=False)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        if dropout:\n",
    "            x = layers.Dropout(0.5)(x)\n",
    "        x = layers.SeparableConv2D(size, 3, strides=1 if pooling else stride, padding='same', use_bias=False)(x)\n",
    "        if pooling:\n",
    "            x = layers.MaxPooling2D(3, strides=stride, padding='same')(x)\n",
    "        if residual:\n",
    "            r = layers.SeparableConv2D(size, 1, strides=stride, padding=\"same\")(\n",
    "                previous_block_activation\n",
    "            )\n",
    "            x = layers.add([x, r])\n",
    "            previous_block_activation = x\n",
    "\n",
    "    return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:50.041237Z",
     "start_time": "2024-01-02T13:02:50.032591Z"
    }
   },
   "id": "5d44da9d85794413"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def base_vgg_16_layers(input):\n",
    "    covnet = keras.applications.vgg16.VGG16(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=img_size + (img_channels,))(covnet)\n",
    "    covnet.trainable = False\n",
    "    return keras.Model(inputs=input, outputs=covnet)\n",
    "\n",
    "\n",
    "def output_vgg_16_layers(covnet):\n",
    "    output = basic_dense_block(covnet, [])\n",
    "    return keras.Model(inputs=covnet, outputs=output)\n",
    "\n",
    "\n",
    "def vgg_16_model():\n",
    "    input = keras.applications.vgg16.preprocess_input(inputs)\n",
    "    covnet = base_vgg_16_layers()(input)\n",
    "    return output_vgg_16_layers(covnet, input)\n",
    "\n",
    "\n",
    "def activate_fine_tuning_on_vgg_16(model):\n",
    "    set_trainable = False\n",
    "    for layer in model.layers:\n",
    "        if layer.name == \"block5_conv1\":\n",
    "            print('Activating fine tuning')\n",
    "            set_trainable = True\n",
    "        if set_trainable:\n",
    "            print(f'Unfreezing layer {layer.name}')\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            print(f'Freezing layer {layer.name}')\n",
    "            layer.trainable = False\n",
    "            \n",
    "        if layer.name == \"vgg16\":\n",
    "            activate_fine_tuning_on_vgg_16(layer)\n",
    "            set_trainable = True\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:25:22.024251Z",
     "start_time": "2024-01-02T13:25:22.011251Z"
    }
   },
   "id": "2243f0d35bf69ff4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output Layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35ca745a6e1390d9"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def basic_dense_block(covnet_param, sizes, global_pooling=False):\n",
    "    if global_pooling:\n",
    "        x = layers.GlobalAveragePooling2D()(covnet_param)\n",
    "    else:\n",
    "        x = layers.Flatten()(covnet_param)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    for size in sizes:\n",
    "        x = layers.Dense(size, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:52.991289Z",
     "start_time": "2024-01-02T13:02:52.967479Z"
    }
   },
   "id": "2d3e86c32901040b"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def Xception_model():\n",
    "    covnet = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(inputs)\n",
    "    covnet = custom_depthwise_conv_block(covnet, [32, 64], 2, stride=2, pooling=True, residual=True)\n",
    "    covnet = custom_depthwise_conv_block(covnet, [128], 2, residual=True)\n",
    "    outputs = basic_dense_block(covnet, [], global_pooling=True)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:53.182656Z",
     "start_time": "2024-01-02T13:02:53.171545Z"
    }
   },
   "id": "6e5f9a14eaffc43a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def vgg_16_k_fold_validation(model_filename):\n",
    "    callbacks_list = [\n",
    "        #    keras.callbacks.EarlyStopping(\n",
    "        #        monitor=\"val_loss\", patience=4\n",
    "        #    ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=model_filename,\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True\n",
    "        ),\n",
    "        #    keras.callbacks.TensorBoard()\n",
    "    ]\n",
    "\n",
    "    i_kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "    history_store = []\n",
    "\n",
    "    for i_result in i_kf.split(labels_df):\n",
    "        i_train = labels_df.iloc[i_result[0]]\n",
    "        i_test = labels_df.iloc[i_result[1]]\n",
    "\n",
    "        print(i_result[0])\n",
    "        print(i_result[1])\n",
    "\n",
    "        display(labels_df)\n",
    "        display(i_train)\n",
    "        print(f'Train size: {len(i_train)}')\n",
    "        display(i_test)\n",
    "        print(f'Test size: {len(i_test)}')\n",
    "\n",
    "        (train_generator, validation_generator) = training_utils.load_generators(i_train, i_test, dataset_path,\n",
    "                                                                                 batch_size, img_size)\n",
    "\n",
    "        conv_base = base_vgg_16_layers()\n",
    "\n",
    "        feature_train = conv_base.predict(train_generator, verbose=1)\n",
    "        feature_val = conv_base.predict(validation_generator, verbose=1)\n",
    "\n",
    "        feature_train = np.concatenate(feature_train)\n",
    "        feature_val = np.concatenate(feature_val)\n",
    "\n",
    "        display(feature_train)\n",
    "\n",
    "        i_model = output_vgg_16_layers(feature_train.shape[1:])\n",
    "\n",
    "        i_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "\n",
    "        i_history = [i_model.fit(feature_train,\n",
    "                                 epochs=epochs,\n",
    "                                 callbacks=callbacks_list,\n",
    "                                 validation_data=feature_val,\n",
    "                                 ), ]\n",
    "\n",
    "        activate_fine_tuning_on_vgg_16(conv_base)\n",
    "        conv_base.add(i_model)\n",
    "        conv_base.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "\n",
    "        i_history.append(conv_base.fit(train_generator,\n",
    "                                       epochs=epochs,\n",
    "                                       callbacks=callbacks_list,\n",
    "                                       validation_data=validation_generator,\n",
    "                                       ))\n",
    "\n",
    "        history_store.append(i_history)\n",
    "\n",
    "    return history_store\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:02:56.814047Z",
     "start_time": "2024-01-02T13:02:56.803256Z"
    }
   },
   "id": "1e9baa3a9d3bd23a",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 240, 320, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 7, 10, 512)        14714688  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 35840)             0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 35840)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               9175296   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23890241 (91.13 MB)\n",
      "Trainable params: 9175553 (35.00 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = vgg_16_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T11:40:11.433140Z",
     "start_time": "2024-01-02T11:40:11.167165Z"
    }
   },
   "id": "e5dd3df119d8e3d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train and compare different models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2300381ac22fbd71"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "# TODO: Try mae vs accuracy. mae should be better since we are adjusting it to get closer to the actual value"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6a1a37a09407565"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    #    keras.callbacks.EarlyStopping(\n",
    "    #        monitor=\"val_loss\", patience=4\n",
    "    #    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_name,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    #    keras.callbacks.TensorBoard()\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b63b6dd1a1758bf6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "result = next(kf.split(labels_df), None)\n",
    "display(labels_df.iloc[result[0]])\n",
    "\n",
    "test = labels_df.iloc[result[1]]\n",
    "display(test)\n",
    "print(result[0])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43f610052a10d5df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all(labels_df.iloc[result[0]]['image_name'].apply(lambda x: isinstance(x, str)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81d7d995553a9bee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def k_fold_validation(i_model):\n",
    "    Wsave = i_model.get_weights()\n",
    "\n",
    "    i_kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "    history_store = []\n",
    "\n",
    "    for i_result in i_kf.split(labels_df):\n",
    "        train = labels_df.iloc[i_result[0]]\n",
    "        test = labels_df.iloc[i_result[1]]\n",
    "\n",
    "        print(i_result[0])\n",
    "        print(i_result[1])\n",
    "\n",
    "        display(labels_df)\n",
    "        display(train)\n",
    "        print(f'Train size: {len(train)}')\n",
    "        display(test)\n",
    "        print(f'Test size: {len(test)}')\n",
    "\n",
    "        (train_generator, validation_generator) = training_utils.load_generators(train, test, dataset_path, batch_size,\n",
    "                                                                                 img_size)\n",
    "\n",
    "        i_model.set_weights(Wsave)\n",
    "        i_history = i_model.fit(train_generator,\n",
    "                                epochs=epochs,\n",
    "                                callbacks=callbacks_list,\n",
    "                                validation_data=validation_generator,\n",
    "                                )\n",
    "\n",
    "        history_store.append(i_history)\n",
    "\n",
    "    return history_store\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78747a7594f941e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#history = k_fold_validation(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3534ba093b0133c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = vgg_16_k_fold_validation(model_name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b79f7c5ac1ccf62"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    #    keras.callbacks.EarlyStopping(\n",
    "    #        monitor=\"val_loss\", patience=4\n",
    "    #    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_name,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    #    keras.callbacks.TensorBoard()\n",
    "]\n",
    "\n",
    "i_kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "history_store = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:03:04.708535Z",
     "start_time": "2024-01-02T13:03:04.694870Z"
    }
   },
   "id": "1edef7ea350e21ef",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    5 ... 1994 1997 1999]\n",
      "[   2    3    4    7   37   45   52   61   65   66   68   69   76   80\n",
      "   82   83   84   85   93  101  112  114  117  119  123  137  142  143\n",
      "  145  154  155  157  161  173  176  180  181  197  199  215  226  230\n",
      "  231  232  236  239  240  241  246  248  263  268  270  271  275  278\n",
      "  280  284  288  294  305  316  323  332  344  352  354  355  356  361\n",
      "  365  368  370  372  376  385  391  401  411  418  426  445  448  452\n",
      "  455  456  458  459  465  468  470  472  479  481  484  488  492  494\n",
      "  501  502  503  505  515  524  526  529  538  540  547  556  557  558\n",
      "  560  570  577  580  581  582  586  598  600  606  610  611  615  619\n",
      "  625  627  633  642  643  652  662  675  677  681  694  695  711  728\n",
      "  735  738  748  768  770  776  786  802  821  823  825  826  835  837\n",
      "  840  844  849  851  852  871  874  880  882  888  891  897  905  909\n",
      "  916  923  928  945  951  952  961  969  978  980  981  985  991  996\n",
      " 1006 1014 1023 1025 1040 1042 1046 1051 1068 1077 1090 1091 1092 1108\n",
      " 1113 1115 1116 1118 1120 1130 1134 1139 1143 1145 1146 1148 1156 1170\n",
      " 1174 1176 1181 1182 1188 1193 1195 1203 1209 1212 1218 1224 1237 1247\n",
      " 1259 1266 1274 1277 1282 1284 1290 1300 1303 1306 1313 1315 1316 1317\n",
      " 1324 1329 1334 1342 1344 1345 1348 1351 1353 1362 1364 1366 1367 1368\n",
      " 1370 1381 1387 1397 1398 1406 1408 1410 1415 1417 1423 1430 1431 1433\n",
      " 1437 1438 1452 1461 1462 1464 1468 1471 1475 1477 1482 1484 1486 1488\n",
      " 1489 1504 1508 1512 1516 1521 1527 1529 1535 1537 1538 1543 1545 1549\n",
      " 1550 1551 1552 1555 1556 1570 1572 1586 1591 1600 1602 1604 1605 1606\n",
      " 1611 1619 1622 1623 1628 1629 1631 1633 1640 1663 1668 1669 1672 1674\n",
      " 1683 1685 1689 1690 1695 1703 1705 1707 1710 1715 1716 1718 1719 1723\n",
      " 1726 1734 1735 1737 1739 1740 1742 1748 1749 1757 1759 1762 1764 1772\n",
      " 1777 1787 1792 1793 1798 1804 1809 1815 1821 1826 1827 1832 1835 1837\n",
      " 1840 1849 1857 1858 1859 1867 1870 1878 1882 1893 1896 1899 1902 1906\n",
      " 1910 1911 1912 1920 1922 1924 1931 1932 1940 1945 1946 1959 1965 1967\n",
      " 1976 1977 1980 1982 1983 1995 1996 1998]\n"
     ]
    },
    {
     "data": {
      "text/plain": "      count      image_name\n0        31  seq_000963.jpg\n1        37  seq_000373.jpg\n2        33  seq_001265.jpg\n3        43  seq_000985.jpg\n4        35  seq_000131.jpg\n...     ...             ...\n1995     36  seq_001110.jpg\n1996     24  seq_001416.jpg\n1997     34  seq_001777.jpg\n1998     30  seq_001445.jpg\n1999     29  seq_000881.jpg\n\n[2000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>seq_000963.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>seq_000373.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>seq_001265.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>43</td>\n      <td>seq_000985.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35</td>\n      <td>seq_000131.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>36</td>\n      <td>seq_001110.jpg</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>24</td>\n      <td>seq_001416.jpg</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>34</td>\n      <td>seq_001777.jpg</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>30</td>\n      <td>seq_001445.jpg</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>29</td>\n      <td>seq_000881.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      count      image_name\n0        31  seq_000963.jpg\n1        37  seq_000373.jpg\n5        36  seq_001570.jpg\n6        23  seq_001530.jpg\n8        43  seq_001618.jpg\n...     ...             ...\n1992     25  seq_000502.jpg\n1993     29  seq_001778.jpg\n1994     30  seq_001747.jpg\n1997     34  seq_001777.jpg\n1999     29  seq_000881.jpg\n\n[1600 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>seq_000963.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>seq_000373.jpg</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>36</td>\n      <td>seq_001570.jpg</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>23</td>\n      <td>seq_001530.jpg</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>43</td>\n      <td>seq_001618.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1992</th>\n      <td>25</td>\n      <td>seq_000502.jpg</td>\n    </tr>\n    <tr>\n      <th>1993</th>\n      <td>29</td>\n      <td>seq_001778.jpg</td>\n    </tr>\n    <tr>\n      <th>1994</th>\n      <td>30</td>\n      <td>seq_001747.jpg</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>34</td>\n      <td>seq_001777.jpg</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>29</td>\n      <td>seq_000881.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>1600 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1600\n"
     ]
    },
    {
     "data": {
      "text/plain": "      count      image_name\n2        33  seq_001265.jpg\n3        43  seq_000985.jpg\n4        35  seq_000131.jpg\n7        35  seq_000150.jpg\n37       32  seq_001694.jpg\n...     ...             ...\n1982     24  seq_000636.jpg\n1983     23  seq_000871.jpg\n1995     36  seq_001110.jpg\n1996     24  seq_001416.jpg\n1998     30  seq_001445.jpg\n\n[400 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>seq_001265.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>43</td>\n      <td>seq_000985.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35</td>\n      <td>seq_000131.jpg</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>35</td>\n      <td>seq_000150.jpg</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>32</td>\n      <td>seq_001694.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1982</th>\n      <td>24</td>\n      <td>seq_000636.jpg</td>\n    </tr>\n    <tr>\n      <th>1983</th>\n      <td>23</td>\n      <td>seq_000871.jpg</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>36</td>\n      <td>seq_001110.jpg</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>24</td>\n      <td>seq_001416.jpg</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>30</td>\n      <td>seq_001445.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 400\n"
     ]
    }
   ],
   "source": [
    "i_result = next(i_kf.split(labels_df), None)\n",
    "i_train = labels_df.iloc[i_result[0]]\n",
    "i_test = labels_df.iloc[i_result[1]]\n",
    "\n",
    "print(i_result[0])\n",
    "print(i_result[1])\n",
    "\n",
    "display(labels_df)\n",
    "display(i_train)\n",
    "print(f'Train size: {len(i_train)}')\n",
    "display(i_test)\n",
    "print(f'Test size: {len(i_test)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:03:05.305766Z",
     "start_time": "2024-01-02T13:03:05.298928Z"
    }
   },
   "id": "8d564c53a20f8d5c",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      count      image_name\n0        31  seq_000963.jpg\n1        37  seq_000373.jpg\n5        36  seq_001570.jpg\n6        23  seq_001530.jpg\n8        43  seq_001618.jpg\n...     ...             ...\n1992     25  seq_000502.jpg\n1993     29  seq_001778.jpg\n1994     30  seq_001747.jpg\n1997     34  seq_001777.jpg\n1999     29  seq_000881.jpg\n\n[1600 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>seq_000963.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>seq_000373.jpg</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>36</td>\n      <td>seq_001570.jpg</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>23</td>\n      <td>seq_001530.jpg</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>43</td>\n      <td>seq_001618.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1992</th>\n      <td>25</td>\n      <td>seq_000502.jpg</td>\n    </tr>\n    <tr>\n      <th>1993</th>\n      <td>29</td>\n      <td>seq_001778.jpg</td>\n    </tr>\n    <tr>\n      <th>1994</th>\n      <td>30</td>\n      <td>seq_001747.jpg</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>34</td>\n      <td>seq_001777.jpg</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>29</td>\n      <td>seq_000881.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>1600 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_name\n",
      "count\n",
      "Found 1600 validated image filenames.\n",
      "Found 400 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "(train_generator, validation_generator) = training_utils.load_generators(i_train, i_test, dataset_path, batch_size,\n",
    "                                                                             img_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:03:06.382223Z",
     "start_time": "2024-01-02T13:03:06.322843Z"
    }
   },
   "id": "a6b93c0f25643a7e",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 240, 320, 3)]     0         \n",
      "                                                                 \n",
      " tf.math.truediv_1 (TFOpLam  (None, 240, 320, 3)       0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " tf.math.subtract_1 (TFOpLa  (None, 240, 320, 3)       0         \n",
      " mbda)                                                           \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 7, 10, 512)        14714688  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = base_vgg_16_layers(keras.layers.Input(shape=img_size + (img_channels,)))\n",
    "conv_base.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:10:59.752970Z",
     "start_time": "2024-01-02T13:10:59.469190Z"
    }
   },
   "id": "7f4a911ce450245b",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 13:11:15.747535: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 21s 2s/step\n",
      "4/4 [==============================] - 5s 2s/step\n"
     ]
    }
   ],
   "source": [
    "feature_train = conv_base.predict(train_generator, 2000, verbose=1)\n",
    "feature_val = conv_base.predict(validation_generator, 2000, verbose=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:11:42.423531Z",
     "start_time": "2024-01-02T13:11:15.128029Z"
    }
   },
   "id": "2f6d442f0bfc54f8",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "feature_train = np.array(feature_train)\n",
    "feature_val = np.array(feature_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:11:55.948658Z",
     "start_time": "2024-01-02T13:11:55.861877Z"
    }
   },
   "id": "f50d04c8bc5d10b4",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 7, 10, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.        , ..., 0.        , 0.75454855,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.6557594 ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.6737831 ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.        , 0.6592682 ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.7134708 ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.72216547,\n        0.        ]], dtype=float32)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31 37 36 ... 30 34 29]\n"
     ]
    }
   ],
   "source": [
    "print(feature_train.shape)\n",
    "display(feature_train[0][0])\n",
    "print(i_train['count'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:11:56.669647Z",
     "start_time": "2024-01-02T13:11:56.663355Z"
    }
   },
   "id": "b601183bb8e8110e",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "i_model = output_vgg_16_layers(keras.Input(shape=feature_train.shape[1:]))\n",
    "\n",
    "i_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:16:30.665360Z",
     "start_time": "2024-01-02T13:16:30.628177Z"
    }
   },
   "id": "524f93562725a2d5",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 139.5435 - mae: 8.8696 - val_loss: 47.9532 - val_mae: 5.4480\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 49.4758 - mae: 5.6200 - val_loss: 47.5855 - val_mae: 5.4845\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.4791 - mae: 5.5989 - val_loss: 47.6868 - val_mae: 5.4931\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.5428 - mae: 5.6067 - val_loss: 47.9094 - val_mae: 5.4453\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 49.0627 - mae: 5.5905 - val_loss: 48.0739 - val_mae: 5.4548\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 48.7027 - mae: 5.5632 - val_loss: 48.5011 - val_mae: 5.4743\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 50.0978 - mae: 5.6599 - val_loss: 48.8482 - val_mae: 5.4872\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 49.4490 - mae: 5.6123 - val_loss: 48.7733 - val_mae: 5.4846\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.5952 - mae: 5.6095 - val_loss: 48.3886 - val_mae: 5.5856\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.2145 - mae: 5.6010 - val_loss: 47.6489 - val_mae: 5.4893\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 49.7227 - mae: 5.6197 - val_loss: 47.6323 - val_mae: 5.4526\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.1874 - mae: 5.6034 - val_loss: 48.3090 - val_mae: 5.4662\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.6075 - mae: 5.6826 - val_loss: 47.5624 - val_mae: 5.4585\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.4362 - mae: 5.5991 - val_loss: 47.8048 - val_mae: 5.5149\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 49.6500 - mae: 5.5940 - val_loss: 49.8897 - val_mae: 5.5180\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.2793 - mae: 5.6678 - val_loss: 47.7652 - val_mae: 5.4449\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.6937 - mae: 5.6767 - val_loss: 48.7658 - val_mae: 5.4844\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 50.0003 - mae: 5.6539 - val_loss: 48.9444 - val_mae: 5.4905\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 50.8285 - mae: 5.6791 - val_loss: 48.8266 - val_mae: 5.4865\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 51.4975 - mae: 5.7145 - val_loss: 52.6656 - val_mae: 5.9109\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 51.4180 - mae: 5.6988 - val_loss: 47.5576 - val_mae: 5.4589\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.5325 - mae: 5.6862 - val_loss: 50.5436 - val_mae: 5.5508\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.3160 - mae: 5.6634 - val_loss: 47.5514 - val_mae: 5.4595\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.4785 - mae: 5.6101 - val_loss: 47.6777 - val_mae: 5.4920\n",
      "Epoch 25/100\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 51.0830 - mae: 5.7059INFO:tensorflow:Assets written to: VGG16_(256).tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: VGG16_(256).tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 12ms/step - loss: 50.3295 - mae: 5.6537 - val_loss: 47.5061 - val_mae: 5.4682\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.5087 - mae: 5.6594 - val_loss: 47.5377 - val_mae: 5.4796\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.1791 - mae: 5.6467 - val_loss: 47.6434 - val_mae: 5.4891\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 51.5963 - mae: 5.7687 - val_loss: 47.7980 - val_mae: 5.5139\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 49.6984 - mae: 5.6059 - val_loss: 48.4376 - val_mae: 5.4719\n",
      "Epoch 30/100\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 49.2671 - mae: 5.5912INFO:tensorflow:Assets written to: VGG16_(256).tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: VGG16_(256).tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 11ms/step - loss: 49.5438 - mae: 5.6202 - val_loss: 47.5040 - val_mae: 5.4719\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 49.6641 - mae: 5.6177 - val_loss: 49.6585 - val_mae: 5.5119\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 50.3280 - mae: 5.6512 - val_loss: 47.6242 - val_mae: 5.4528\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 49.5703 - mae: 5.6213 - val_loss: 47.6807 - val_mae: 5.4924\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 49.9540 - mae: 5.6477 - val_loss: 47.8558 - val_mae: 5.4423\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.2136 - mae: 5.6352 - val_loss: 48.7194 - val_mae: 5.6147\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.9126 - mae: 5.6799 - val_loss: 47.6274 - val_mae: 5.4881\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.7404 - mae: 5.6290 - val_loss: 50.7273 - val_mae: 5.5608\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.8583 - mae: 5.6337 - val_loss: 49.3836 - val_mae: 5.5042\n",
      "Epoch 39/100\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 50.4700 - mae: 5.6620INFO:tensorflow:Assets written to: VGG16_(256).tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: VGG16_(256).tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 12ms/step - loss: 49.9097 - mae: 5.6301 - val_loss: 47.5012 - val_mae: 5.4697\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 50.1792 - mae: 5.6903 - val_loss: 48.9229 - val_mae: 5.6306\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.9202 - mae: 5.7192 - val_loss: 51.2104 - val_mae: 5.8138\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.9230 - mae: 5.7061 - val_loss: 47.5049 - val_mae: 5.4669\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 50.7218 - mae: 5.6431 - val_loss: 49.8533 - val_mae: 5.5172\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 49.7812 - mae: 5.6221 - val_loss: 48.1203 - val_mae: 5.4575\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 49.6668 - mae: 5.6073 - val_loss: 47.5084 - val_mae: 5.4749\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 50.9433 - mae: 5.7070 - val_loss: 47.7146 - val_mae: 5.4994\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.8768 - mae: 5.6471 - val_loss: 47.5799 - val_mae: 5.4845\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.7335 - mae: 5.6727 - val_loss: 48.9760 - val_mae: 5.4917\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.6435 - mae: 5.7026 - val_loss: 47.5107 - val_mae: 5.4757\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.7120 - mae: 5.6153 - val_loss: 47.5496 - val_mae: 5.4589\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.9650 - mae: 5.6387 - val_loss: 48.9514 - val_mae: 5.4909\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.4566 - mae: 5.7111 - val_loss: 50.3167 - val_mae: 5.5385\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 51.1197 - mae: 5.6955 - val_loss: 47.5463 - val_mae: 5.4813\n",
      "Epoch 54/100\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 50.5277 - mae: 5.6615INFO:tensorflow:Assets written to: VGG16_(256).tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: VGG16_(256).tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 12ms/step - loss: 50.2244 - mae: 5.6539 - val_loss: 47.5001 - val_mae: 5.4731\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.0668 - mae: 5.6330 - val_loss: 47.9549 - val_mae: 5.5374\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 50.1975 - mae: 5.6463 - val_loss: 47.5088 - val_mae: 5.4647\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 51.1329 - mae: 5.7083 - val_loss: 47.5472 - val_mae: 5.4589\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 51.2060 - mae: 5.6995 - val_loss: 49.0774 - val_mae: 5.4951\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.2737 - mae: 5.6796 - val_loss: 48.5038 - val_mae: 5.5962\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.9253 - mae: 5.6782 - val_loss: 50.9024 - val_mae: 5.7909\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 51.7449 - mae: 5.7447 - val_loss: 47.7699 - val_mae: 5.5098\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.4994 - mae: 5.6961 - val_loss: 48.7461 - val_mae: 5.6168\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 51.1876 - mae: 5.6830 - val_loss: 47.8487 - val_mae: 5.5224\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.2791 - mae: 5.6867 - val_loss: 51.3380 - val_mae: 5.8229\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.5606 - mae: 5.7072 - val_loss: 50.0501 - val_mae: 5.5234\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.8016 - mae: 5.6794 - val_loss: 49.8575 - val_mae: 5.5174\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 50.2514 - mae: 5.6709 - val_loss: 48.8413 - val_mae: 5.4873\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 49.5225 - mae: 5.6109 - val_loss: 48.6557 - val_mae: 5.4807\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 51.1254 - mae: 5.7155 - val_loss: 50.7784 - val_mae: 5.5638\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.2980 - mae: 5.6681 - val_loss: 47.9052 - val_mae: 5.4458\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 50.0189 - mae: 5.6570 - val_loss: 50.3051 - val_mae: 5.5380\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 50.2702 - mae: 5.6671 - val_loss: 50.2814 - val_mae: 5.5367\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 51.4700 - mae: 5.7221 - val_loss: 47.5474 - val_mae: 5.4817\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.8963 - mae: 5.6368 - val_loss: 47.5898 - val_mae: 5.4857\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.5151 - mae: 5.6520 - val_loss: 47.9122 - val_mae: 5.5318\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 50.7898 - mae: 5.6822 - val_loss: 48.2131 - val_mae: 5.5680\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 50.0045 - mae: 5.6306 - val_loss: 47.6633 - val_mae: 5.4910\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 49.7915 - mae: 5.6344 - val_loss: 47.5147 - val_mae: 5.4626\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 51.4010 - mae: 5.7318 - val_loss: 50.6091 - val_mae: 5.7680\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.7837 - mae: 5.6661 - val_loss: 47.6678 - val_mae: 5.4491\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 50.1282 - mae: 5.6384 - val_loss: 48.2465 - val_mae: 5.4639\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.8972 - mae: 5.7301 - val_loss: 47.5423 - val_mae: 5.4813\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 49.9197 - mae: 5.6492 - val_loss: 48.6843 - val_mae: 5.4818\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.3040 - mae: 5.6519 - val_loss: 47.5408 - val_mae: 5.4589\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 51.4829 - mae: 5.7132 - val_loss: 47.5058 - val_mae: 5.4639\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.1319 - mae: 5.6207 - val_loss: 48.4427 - val_mae: 5.4725\n",
      "Epoch 87/100\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 50.9701 - mae: 5.6712INFO:tensorflow:Assets written to: VGG16_(256).tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: VGG16_(256).tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 12ms/step - loss: 50.9718 - mae: 5.6816 - val_loss: 47.4910 - val_mae: 5.4701\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.7626 - mae: 5.6901 - val_loss: 49.9667 - val_mae: 5.5205\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.7571 - mae: 5.7152 - val_loss: 48.7763 - val_mae: 5.4851\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 51.9774 - mae: 5.6885 - val_loss: 52.6252 - val_mae: 5.6500\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 51.4854 - mae: 5.7297 - val_loss: 47.8093 - val_mae: 5.4422\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 51.4740 - mae: 5.7796 - val_loss: 51.4845 - val_mae: 5.8331\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 52.1368 - mae: 5.7643 - val_loss: 50.2450 - val_mae: 5.5348\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 50.1071 - mae: 5.6498 - val_loss: 47.5738 - val_mae: 5.4554\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 51.5312 - mae: 5.7488 - val_loss: 47.7450 - val_mae: 5.5059\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 49.9142 - mae: 5.6459 - val_loss: 48.2030 - val_mae: 5.4621\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 51.1826 - mae: 5.7105 - val_loss: 47.5191 - val_mae: 5.4613\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.3199 - mae: 5.6557 - val_loss: 50.2049 - val_mae: 5.5325\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.9869 - mae: 5.6775 - val_loss: 48.5210 - val_mae: 5.4757\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 50.1075 - mae: 5.6443 - val_loss: 47.5286 - val_mae: 5.4599\n"
     ]
    }
   ],
   "source": [
    "dense_history = i_model.fit(feature_train, i_train['count'].values,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks_list,\n",
    "            validation_data=(feature_val, i_test['count'].values),\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:17:16.172272Z",
     "start_time": "2024-01-02T13:16:30.892282Z"
    }
   },
   "id": "10d6277f97b146c3",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "i_model_weights = i_model.get_weights()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:18:40.013108Z",
     "start_time": "2024-01-02T13:18:39.972184Z"
    }
   },
   "id": "2b1811a107b9bbb7",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer input_6\n",
      "Freezing layer tf.math.truediv_1\n",
      "Freezing layer tf.math.subtract_1\n",
      "Freezing layer vgg16\n",
      "Freezing layer input_7\n",
      "Freezing layer block1_conv1\n",
      "Freezing layer block1_conv2\n",
      "Freezing layer block1_pool\n",
      "Freezing layer block2_conv1\n",
      "Freezing layer block2_conv2\n",
      "Freezing layer block2_pool\n",
      "Freezing layer block3_conv1\n",
      "Freezing layer block3_conv2\n",
      "Freezing layer block3_conv3\n",
      "Freezing layer block3_pool\n",
      "Freezing layer block4_conv1\n",
      "Freezing layer block4_conv2\n",
      "Freezing layer block4_conv3\n",
      "Freezing layer block4_pool\n",
      "Activating fine tuning\n",
      "Unfreezing layer block5_conv1\n",
      "Unfreezing layer block5_conv2\n",
      "Unfreezing layer block5_conv3\n",
      "Unfreezing layer block5_pool\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 240, 320, 3)]     0         \n",
      "                                                                 \n",
      " tf.math.truediv_1 (TFOpLam  (None, 240, 320, 3)       0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " tf.math.subtract_1 (TFOpLa  (None, 240, 320, 3)       0         \n",
      " mbda)                                                           \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 7, 10, 512)        14714688  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "activate_fine_tuning_on_vgg_16(conv_base)\n",
    "conv_base.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:25:43.086613Z",
     "start_time": "2024-01-02T13:25:43.053054Z"
    }
   },
   "id": "66e87c173777fcc8",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer input_6\n",
      "Freezing layer tf.math.truediv_1\n",
      "Freezing layer tf.math.subtract_1\n",
      "Freezing layer vgg16\n",
      "Freezing layer input_7\n",
      "Freezing layer block1_conv1\n",
      "Freezing layer block1_conv2\n",
      "Freezing layer block1_pool\n",
      "Freezing layer block2_conv1\n",
      "Freezing layer block2_conv2\n",
      "Freezing layer block2_pool\n",
      "Freezing layer block3_conv1\n",
      "Freezing layer block3_conv2\n",
      "Freezing layer block3_conv3\n",
      "Freezing layer block3_pool\n",
      "Freezing layer block4_conv1\n",
      "Freezing layer block4_conv2\n",
      "Freezing layer block4_conv3\n",
      "Freezing layer block4_pool\n",
      "Activating fine tuning\n",
      "Unfreezing layer block5_conv1\n",
      "Unfreezing layer block5_conv2\n",
      "Unfreezing layer block5_conv3\n",
      "Unfreezing layer block5_pool\n",
      "Unfreezing layer model_5\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 240, 320, 3)]     0         \n",
      "                                                                 \n",
      " tf.math.truediv_1 (TFOpLam  (None, 240, 320, 3)       0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " tf.math.subtract_1 (TFOpLa  (None, 240, 320, 3)       0         \n",
      " mbda)                                                           \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 7, 10, 512)        14714688  \n",
      "                                                                 \n",
      " model_5 (Functional)        (None, 1)                 35841     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14750529 (56.27 MB)\n",
      "Trainable params: 35841 (140.00 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "merged_model = keras.Model(inputs=conv_base.input, outputs=i_model(conv_base.output))\n",
    "activate_fine_tuning_on_vgg_16(merged_model)\n",
    "merged_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T13:26:29.225351Z",
     "start_time": "2024-01-02T13:26:29.190807Z"
    }
   },
   "id": "967ec62e89acbf1f",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "merged_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T12:30:43.972714Z",
     "start_time": "2024-01-02T12:30:43.964742Z"
    }
   },
   "id": "d91973c8927ee2bc",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 7, 10, 512)]      0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 35840)             0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 35840)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               9175296   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9175553 (35.00 MB)\n",
      "Trainable params: 9175553 (35.00 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "i_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T12:38:53.511993Z",
     "start_time": "2024-01-02T12:38:53.482834Z"
    }
   },
   "id": "41d5d46d3c18ce5b",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 31s 2s/step - loss: 880337.8125 - mae: 441.4072 - val_loss: 107078.2969 - val_mae: 266.8619\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 29s 2s/step - loss: 3246022.0000 - mae: 1281.9241 - val_loss: 349751.8438 - val_mae: 572.9822\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 29s 2s/step - loss: 1568020224.0000 - mae: 24467.4707 - val_loss: 123157472.0000 - val_mae: 9835.6914\n",
      "Epoch 4/50\n",
      " 9/13 [===================>..........] - ETA: 6s - loss: 25955911680.0000 - mae: 116002.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[59], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m conv_history \u001B[38;5;241m=\u001B[39m merged_model\u001B[38;5;241m.\u001B[39mfit(train_generator,\n\u001B[1;32m      2\u001B[0m             epochs\u001B[38;5;241m=\u001B[39mepochs,\n\u001B[1;32m      3\u001B[0m             callbacks\u001B[38;5;241m=\u001B[39mcallbacks_list,\n\u001B[1;32m      4\u001B[0m             validation_data\u001B[38;5;241m=\u001B[39mvalidation_generator,\n\u001B[1;32m      5\u001B[0m             )\n",
      "File \u001B[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1781\u001B[0m ):\n\u001B[1;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function(iterator)\n\u001B[1;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m tracing_compilation\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[1;32m    868\u001B[0m       args, kwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_config\n\u001B[1;32m    869\u001B[0m   )\n\u001B[1;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m function\u001B[38;5;241m.\u001B[39m_call_flat(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    140\u001B[0m     flat_inputs, captured_inputs\u001B[38;5;241m=\u001B[39mfunction\u001B[38;5;241m.\u001B[39mcaptured_inputs\n\u001B[1;32m    141\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inference_function\u001B[38;5;241m.\u001B[39mflat_call(args)\n\u001B[1;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1266\u001B[0m     args,\n\u001B[1;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1268\u001B[0m     executing_eagerly)\n\u001B[1;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[1;32m    253\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m    254\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    255\u001B[0m         \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mflat_outputs),\n\u001B[1;32m    256\u001B[0m     )\n\u001B[1;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    262\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute(\n\u001B[1;32m   1480\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1481\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   1482\u001B[0m       inputs\u001B[38;5;241m=\u001B[39mtensor_inputs,\n\u001B[1;32m   1483\u001B[0m       attrs\u001B[38;5;241m=\u001B[39mattrs,\n\u001B[1;32m   1484\u001B[0m       ctx\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1485\u001B[0m   )\n\u001B[1;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1494\u001B[0m   )\n",
      "File \u001B[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[1;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[1;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[1;32m     59\u001B[0m   ]\n\u001B[0;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     61\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "conv_history = merged_model.fit(train_generator,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks_list,\n",
    "            validation_data=validation_generator,\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T12:32:42.211341Z",
     "start_time": "2024-01-02T12:30:54.811402Z"
    }
   },
   "id": "498355d634f846ef",
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Represent history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58e86b9fe03737d3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(history)\n",
    "mea_results = [np.min(x.history['mae']) for x in history]\n",
    "val_mea_results = [np.min(x.history['val_mae']) for x in history]\n",
    "loss_results = [np.min(x.history['loss']) for x in history]\n",
    "val_loss_results = [np.min(x.history['val_loss']) for x in history]\n",
    "print(mea_results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10dc65f492c53884",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f'Mean mae: {np.mean(mea_results)}')\n",
    "print(f'Mean val_mae: {np.mean(val_mea_results)}')\n",
    "print(f'Mean loss: {np.mean(loss_results)}')\n",
    "print(f'Mean val_loss: {np.mean(val_loss_results)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac3cb68a86eb22d2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(history[0].history.keys())\n",
    "history_single = history[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67717d62f31c0b32"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# history_single = history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a8f97a282db789c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history_single.history['mae'][display_epochs[0]:display_epochs[1]])\n",
    "plt.plot(history_single.history['val_mae'][display_epochs[0]:display_epochs[1]])\n",
    "plt.title('model mean squared')\n",
    "plt.ylabel('mean squared')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e75911e361ab876"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history_single.history['loss'][display_epochs[0]:display_epochs[1]])\n",
    "plt.plot(history_single.history['val_loss'][display_epochs[0]:display_epochs[1]])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5127fc57c23c9c46"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3a716f44ce89aba5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8a8e2b64bc24f180"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bibliografia\n",
    "\n",
    "- Deep Learning with Python, Second Edition. François Chollet\n",
    "- https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "Dataset citation:\n",
    "- From Semi-Supervised to Transfer Counting of Crowds\n",
    "C. C. Loy, S. Gong, and T. Xiang\n",
    "in Proceedings of IEEE International Conference on Computer Vision, pp. 2256-2263, 2013 (ICCV)\n",
    "- Cumulative Attribute Space for Age and Crowd Density Estimation\n",
    "K. Chen, S. Gong, T. Xiang, and C. C. Loy\n",
    "in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 2467-2474, 2013 (CVPR, Oral)\n",
    "- Crowd Counting and Profiling: Methodology and Evaluation\n",
    "C. C. Loy, K. Chen, S. Gong, T. Xiang\n",
    "in S. Ali, K. Nishino, D. Manocha, and M. Shah (Eds.), Modeling, Simulation and Visual Analysis of Crowds, Springer, vol. 11, pp. 347-382, 2013\n",
    "- Feature Mining for Localised Crowd Counting\n",
    "K. Chen, C. C. Loy, S. Gong, and T. Xiang\n",
    "British Machine Vision Conference, 2012 (BMVC)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13d04d940c127e7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d9e58f5fbb53a5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
