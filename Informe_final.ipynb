{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:23:20.779776Z",
     "start_time": "2024-01-03T16:23:20.774601Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras.layers as layers\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import training_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configuracion "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4485b1477b71e54e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img_size=(240, 320)\n",
    "img_channels = 3\n",
    "batch_size=32\n",
    "epochs = 50\n",
    "display_epochs = (0, 100)\n",
    "inputs = keras.Input(shape= img_size + (img_channels,))\n",
    "debug = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:23:22.696091Z",
     "start_time": "2024-01-03T16:23:22.691284Z"
    }
   },
   "id": "6478014e16b476d8",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "68d898fe4e70bce4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset_path = '/Users/olove/Library/CloudStorage/OneDrive-Personal/AI datasets/CrowdCounter'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:23:24.520129Z",
     "start_time": "2024-01-03T16:23:24.516117Z"
    }
   },
   "id": "4981a6785e45d3e5",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Carga de los datos\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db752258c98ba6dc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      count      image_name\n0        31  seq_001125.jpg\n1        36  seq_000247.jpg\n2        22  seq_000887.jpg\n3        47  seq_000709.jpg\n4        29  seq_001436.jpg\n...     ...             ...\n1995     29  seq_001973.jpg\n1996     24  seq_000010.jpg\n1997     30  seq_001115.jpg\n1998     30  seq_001941.jpg\n1999     22  seq_001483.jpg\n\n[2000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>seq_001125.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36</td>\n      <td>seq_000247.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22</td>\n      <td>seq_000887.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47</td>\n      <td>seq_000709.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29</td>\n      <td>seq_001436.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>29</td>\n      <td>seq_001973.jpg</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>24</td>\n      <td>seq_000010.jpg</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>30</td>\n      <td>seq_001115.jpg</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>30</td>\n      <td>seq_001941.jpg</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>22</td>\n      <td>seq_001483.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(dataset_path + '/labels.csv')\n",
    "labels_df['image_name'] = labels_df['id'].map('seq_{:06d}.jpg'.format)\n",
    "labels_df.drop(\"id\", axis=1,inplace=True)\n",
    "labels_df = labels_df.sample(frac=1).reset_index(drop=True)\n",
    "display(labels_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:23:25.351281Z",
     "start_time": "2024-01-03T16:23:25.312131Z"
    }
   },
   "id": "aafb39e4f0d5c1c1",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introducción\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc9c316a8fb75d9d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Baseline sencillo\n",
    "\n",
    "Durante este entrenamiento vamos a estar utilizando el mae para medir la calidad de los modelos.\n",
    "Pera ver si nuestros modelos realmente estan aprendiendo vamos a utilizar un baseline sencillo que consiste en predecir la media de la distribución de los datos de entrenamiento."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b5e55e6bb147304"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE: 5.5322575\n"
     ]
    }
   ],
   "source": [
    "baseline_mae = np.mean(np.abs(labels_df['count'] - np.mean(labels_df['count'])))\n",
    "print(f'Baseline MAE: {baseline_mae}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:24:40.884802Z",
     "start_time": "2024-01-03T16:24:40.868094Z"
    }
   },
   "id": "da3bedb91b9fe46f",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "Con esto podemos ver que una solución sencilla tiene un MAE de 5.53. Por lo tanto cualquier modelo que no supere este valor no estará aprendiendo una solución util a este problema."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8c5124234123367"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Procedimiento de evaluación de los modelos\n",
    "\n",
    "Para evaluar los modelos se va a utilizar una validación k-fold. \n",
    "Esto es debido a que el dataset es pequeño y al entrenar se aprecia que hay mucha variablilidad en el resultado de la validación.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b76d01f46337aeef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def k_fold_validation(i_model, model_filename):\n",
    "\n",
    "    callbacks_list = [\n",
    "        #    keras.callbacks.EarlyStopping(\n",
    "        #        monitor=\"val_loss\", patience=4\n",
    "        #    ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=model_filename,\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True\n",
    "        ),\n",
    "        #    keras.callbacks.TensorBoard()\n",
    "    ]\n",
    "    \n",
    "    # Guradamos los pesos iniciales del modelo para poder reiniciarlos en cada iteración sin tener que re compilar/contruir el modelo\n",
    "    Wsave = i_model.get_weights()\n",
    "\n",
    "    i_kf = KFold(n_splits = 5, shuffle = True, random_state = 2)\n",
    "\n",
    "    history_store = []\n",
    "\n",
    "    for i_result in i_kf.split(labels_df):\n",
    "\n",
    "        train = labels_df.iloc[i_result[0]]\n",
    "        test =  labels_df.iloc[i_result[1]]\n",
    "\n",
    "        if debug:\n",
    "            print(i_result[0])\n",
    "            print(i_result[1])\n",
    "\n",
    "            display(labels_df)\n",
    "            display(train)\n",
    "            print(f'Train size: {len(train)}')\n",
    "            display(test)\n",
    "            print(f'Test size: {len(test)}')\n",
    "\n",
    "        (train_generator, validation_generator) = training_utils.load_generators(train, test, dataset_path, batch_size, img_size)\n",
    "\n",
    "        i_model.set_weights(Wsave)\n",
    "        i_history = i_model.fit(train_generator,\n",
    "                                epochs=epochs,\n",
    "                                callbacks = callbacks_list,\n",
    "                                validation_data=validation_generator,\n",
    "                                )\n",
    "\n",
    "        history_store.append(i_history)\n",
    "\n",
    "    return history_store\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29f823b67005a62f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Los Modelos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ddc0d18782becae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelos convulucionales simples\n",
    "\n",
    "Como primer modelo intentamos eperimentar con modelos convulucionales simples.\n",
    "Para ellos utilizaremos unicamente unas capas convulucionales y unas capas densas sin nungun otro añadido.\n",
    "\n",
    "Con esto pretendemos ver si un modelo convulucional puede aprender o superar nuestra solución baseline."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17d1fdc2820f85c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def basic_covnet_block():\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, strides=2, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10ee1b3c396e58ca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "covnet_block = basic_covnet_block()\n",
    "x = layers.Flatten()(covnet_block)\n",
    "x = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=x)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5738654b580b0da",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e57d9abe1f55317",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "k_fold_validation(model, 'basic_covnet_(32, 64,128)_NaN.h5')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d5593dcde0f11ed",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo con VGG16 como extractor de features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ff6bfce7a94fe73"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def base_vgg_16_layers(input):\n",
    "    covnet = keras.applications.vgg16.VGG16(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=img_size + (img_channels,))(covnet)\n",
    "    covnet.trainable = False\n",
    "    return keras.Model(inputs=input, outputs=covnet)\n",
    "\n",
    "\n",
    "def output_vgg_16_layers(covnet):\n",
    "    output = basic_dense_block(covnet, [])\n",
    "    return keras.Model(inputs=covnet, outputs=output)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfbd34a0927a0c19"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def activate_fine_tuning_on_vgg_16(ft_model):\n",
    "    # Flag to indicate whether the layers should be trainable\n",
    "    set_trainable = False\n",
    "\n",
    "    # Assuming 'vgg16' is the name of the nested VGG16 model\n",
    "    vgg16 = ft_model.get_layer('vgg16')\n",
    "    vgg16.trainable = True\n",
    "\n",
    "    for layer in vgg16.layers:\n",
    "        # Start fine-tuning from 'block5_conv1'\n",
    "        if layer.name == 'block5_conv1':\n",
    "            set_trainable = True\n",
    "\n",
    "        # Set the trainable flag for the layers\n",
    "        if set_trainable:\n",
    "            print(f'Unfreezing layer {layer.name}')\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            print(f'Freezing layer {layer.name}')\n",
    "            layer.trainable = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ce2e937c917f88a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def vgg_16_k_fold_validation(model_filename):\n",
    "    callbacks_list = [\n",
    "        #    keras.callbacks.EarlyStopping(\n",
    "        #        monitor=\"val_loss\", patience=4\n",
    "        #    ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=model_filename,\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True\n",
    "        ),\n",
    "        #    keras.callbacks.TensorBoard()\n",
    "    ]\n",
    "\n",
    "    i_kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "    history_store = []\n",
    "\n",
    "    for i_result in i_kf.split(labels_df):\n",
    "        i_train = labels_df.iloc[i_result[0]]\n",
    "        i_test = labels_df.iloc[i_result[1]]\n",
    "\n",
    "        if debug:\n",
    "            print(i_result[0])\n",
    "            print(i_result[1])\n",
    "\n",
    "            display(labels_df)\n",
    "            display(i_train)\n",
    "            print(f'Train size: {len(i_train)}')\n",
    "            display(i_test)\n",
    "            print(f'Test size: {len(i_test)}')\n",
    "\n",
    "        (train_generator, validation_generator) = training_utils.load_generators(i_train, i_test, dataset_path,\n",
    "                                                                                 batch_size, img_size)\n",
    "\n",
    "        conv_base = base_vgg_16_layers(keras.layers.Input(shape=img_size + (img_channels,)))\n",
    "\n",
    "        feature_train = conv_base.predict(train_generator, 2000, verbose=1)\n",
    "        feature_val = conv_base.predict(validation_generator, 2000, verbose=1)\n",
    "\n",
    "        feature_train = np.array(feature_train)\n",
    "        feature_val = np.array(feature_val)\n",
    "\n",
    "        if debug:\n",
    "            print(feature_train.shape)\n",
    "            display(feature_train[0][0])\n",
    "            print(i_train['count'].values)\n",
    "\n",
    "        i_model = output_vgg_16_layers(keras.Input(shape=feature_train.shape[1:]))\n",
    "\n",
    "        i_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "\n",
    "        i_history = [i_model.fit(feature_train, i_train['count'].values,\n",
    "                                 epochs=epochs,\n",
    "                                 callbacks=callbacks_list,\n",
    "                                 validation_data=(feature_val, i_test['count'].values),\n",
    "                                 ), ]\n",
    "\n",
    "        merged_model = keras.Model(inputs=conv_base.input, outputs=i_model(conv_base.output))\n",
    "        activate_fine_tuning_on_vgg_16(merged_model)\n",
    "        merged_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "\n",
    "        merged_model.summary()\n",
    "\n",
    "        i_history.append(merged_model.fit(train_generator,\n",
    "                                          epochs=epochs,\n",
    "                                          callbacks=callbacks_list,\n",
    "                                          validation_data=validation_generator,\n",
    "                                          ))\n",
    "\n",
    "        history_store.append(i_history)\n",
    "\n",
    "    return history_store\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc411fae78c25f3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
